{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "young-reproduction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-93cd47710814>:33: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87783456]]\n",
      "[[0.9392106]]\n",
      "[[0.68043333]]\n",
      "[[0.771839]]\n",
      "[[0.68989617]]\n",
      "[[0.63136834]]\n",
      "[[0.68756104]]\n",
      "[[0.34842268]]\n",
      "[[0.37965304]]\n",
      "[[0.3473497]]\n",
      "[[0.49545375]]\n",
      "[[0.32930604]]\n",
      "[[0.28600296]]\n",
      "[[0.82012]]\n",
      "[[0.80351317]]\n",
      "[[0.55621874]]\n",
      "[[0.7376966]]\n",
      "[[0.7789035]]\n",
      "[[0.6703783]]\n",
      "[[0.40927356]]\n",
      "[[0.5698042]]\n",
      "[[0.3605757]]\n",
      "[[0.5542224]]\n",
      "[[0.13044414]]\n",
      "[[0.21022063]]\n",
      "[[0.16431269]]\n",
      "[[0.2727813]]\n",
      "[[0.15002963]]\n",
      "[[0.4703032]]\n",
      "[[0.5768209]]\n",
      "[[0.6473392]]\n",
      "[[0.67632306]]\n",
      "[[0.56275487]]\n",
      "[[0.6204139]]\n",
      "[[0.4177953]]\n",
      "[[0.75596654]]\n",
      "[[0.746976]]\n",
      "[[0.8098114]]\n",
      "[[0.5342509]]\n",
      "[[0.59270644]]\n",
      "[[0.53715193]]\n",
      "[[0.76463175]]\n",
      "[[0.72889054]]\n",
      "[[0.82871914]]\n",
      "[[0.6750848]]\n",
      "[[0.6993667]]\n",
      "[[0.03805441]]\n",
      "[[0.01453099]]\n",
      "[[0.6845877]]\n",
      "[[0.8851383]]\n",
      "[[0.7381931]]\n",
      "[[0.9053663]]\n",
      "[[0.8052785]]\n",
      "[[0.8864622]]\n",
      "[[0.76027685]]\n",
      "[[0.88188195]]\n",
      "[[0.9017212]]\n",
      "[[0.83628273]]\n",
      "[[0.00909629]]\n",
      "[[0.02018419]]\n",
      "[[0.008771]]\n",
      "[[0.01277682]]\n",
      "[[0.01307553]]\n",
      "[[0.01958689]]\n",
      "[[0.34125155]]\n",
      "[[0.4696759]]\n",
      "[[0.01796049]]\n",
      "[[0.25160775]]\n",
      "[[0.47888634]]\n",
      "[[0.5325839]]\n",
      "[[0.37301415]]\n",
      "[[0.2973841]]\n",
      "[[0.49174613]]\n",
      "[[0.4273569]]\n",
      "[[0.16038242]]\n",
      "[[0.01778206]]\n",
      "[[0.01813027]]\n",
      "[[0.02166525]]\n",
      "[[0.0142366]]\n",
      "[[0.03542548]]\n",
      "[[0.03693759]]\n",
      "[[0.03904983]]\n",
      "[[0.02599442]]\n",
      "[[0.0240373]]\n",
      "[[0.01479879]]\n",
      "[[0.02461684]]\n",
      "[[0.12706861]]\n",
      "[[0.41613266]]\n",
      "[[0.20959896]]\n",
      "[[0.32659337]]\n",
      "[[0.4726174]]\n",
      "[[0.30604416]]\n",
      "[[0.02043366]]\n",
      "[[0.1925647]]\n",
      "[[0.8631326]]\n",
      "[[0.8480524]]\n",
      "[[0.8883306]]\n",
      "[[0.02229357]]\n",
      "[[0.7409142]]\n",
      "[[0.63040566]]\n",
      "[[0.4433723]]\n",
      "[[0.44766912]]\n",
      "[[0.46947315]]\n",
      "[[0.3204836]]\n",
      "[[0.4106874]]\n",
      "[[0.46730515]]\n",
      "[[0.36993092]]\n",
      "[[0.6213774]]\n",
      "[[0.48285455]]\n",
      "[[0.45647767]]\n",
      "[[0.3410978]]\n",
      "[[0.33869606]]\n",
      "[[0.3951199]]\n",
      "[[0.3102254]]\n",
      "[[0.36525348]]\n",
      "[[0.23526636]]\n",
      "[[0.31811202]]\n",
      "[[0.24077478]]\n",
      "[[0.8937658]]\n",
      "[[0.8295933]]\n",
      "[[0.84112585]]\n",
      "[[0.8722757]]\n",
      "[[0.84906936]]\n",
      "[[0.55824983]]\n",
      "[[0.6113525]]\n",
      "[[0.9169498]]\n",
      "[[0.54437673]]\n",
      "[[0.02547595]]\n",
      "[[0.91164476]]\n",
      "[[0.94575775]]\n",
      "[[0.9679676]]\n",
      "[[0.96823895]]\n",
      "[[0.97509754]]\n",
      "[[0.7200073]]\n",
      "[[0.6949278]]\n",
      "[[0.671797]]\n",
      "[[0.5779047]]\n",
      "[[0.75811]]\n",
      "[[0.8694476]]\n",
      "[[0.8829715]]\n",
      "[[0.884565]]\n",
      "[[0.78246045]]\n",
      "[[0.86735976]]\n",
      "[[0.01472655]]\n",
      "[[0.01245394]]\n",
      "[[0.00808045]]\n",
      "[[0.01380622]]\n",
      "[[0.0101468]]\n",
      "[[0.01509342]]\n",
      "[[0.01111627]]\n"
     ]
    }
   ],
   "source": [
    "####eyeML\n",
    "# 1. 얼굴 영역 검출\n",
    "# 2. 얼굴 영역 속 눈 영역 검출\n",
    "# 3. 왼쪽, 오른쪽 둘다 검출\n",
    "# 4. 카메라 이미지 전처리\n",
    "# 5. 모델에 적용 및 라벨링\n",
    "# 6. 출력\n",
    "'''\n",
    "anaconda prompt 에서 가상환경 설치 후 -->  conda install -c conda-forge dlib\n",
    "'''\n",
    "import cv2, dlib\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from imutils import face_utils\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "def crop_eye(img, eye_points):\n",
    "    x1, y1 = np.amin(eye_points, axis=0)\n",
    "    x2, y2 = np.amax(eye_points, axis=0)\n",
    "    cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
    "\n",
    "    w = (x2 - x1) * 1.2\n",
    "    h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
    "\n",
    "    margin_x, margin_y = w / 2, h / 2\n",
    "\n",
    "    min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
    "    max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
    "\n",
    "    eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
    "\n",
    "    eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
    "\n",
    "    return eye_img, eye_rect\n",
    "\n",
    "\n",
    "\n",
    "IMG_SIZE = (34, 26)\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('cascadeclassifier/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Face,eyes detection XML load and trained model loading\n",
    "#face_detection = cv2.CascadeClassifier('cascadeclassifier/haarcascade_frontalface_default.xml')\n",
    "#eye_detection = cv2.CascadeClassifier('cascadeclassifier/haarcascade_eye.xml')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#모델 불러오기\n",
    "eye_model = load_model('models/2021_02_03_15_05_07.h5')\n",
    "#eye_model.summary()\n",
    "\n",
    "#웹캠 열기\n",
    "try:\n",
    "    camera = cv2.VideoCapture(0)\n",
    "except:\n",
    "    print(\"camera loading error\\n\")\n",
    "\n",
    "    \n",
    "while camera.isOpened(): #카메라 on\n",
    "    \n",
    "    # read frame from webcam\n",
    "    ret, img_ori = camera.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    \n",
    "    img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
    "\n",
    "    img = img_ori.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = detector(gray)\n",
    "\n",
    "    for face in faces:\n",
    "        shapes = predictor(gray, face)\n",
    "        shapes = face_utils.shape_to_np(shapes)\n",
    "\n",
    "        eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
    "        eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
    "\n",
    "        eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
    "        eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
    "\n",
    "        #창 2개 따로 생성\n",
    "        cv2.imshow('l', eye_img_l) \n",
    "        cv2.imshow('r', eye_img_r)\n",
    "\n",
    "        eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "        eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32) / 255.\n",
    "\n",
    "        pred_l = eye_model.predict(eye_input_l)\n",
    "        pred_r = eye_model.predict(eye_input_r)\n",
    "        \n",
    "        #print(pred_l)\n",
    "\n",
    "        # visualize\n",
    "        state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
    "        state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
    "\n",
    "        state_l = state_l % pred_l\n",
    "        state_r = state_r % pred_r\n",
    "\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
    "        cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
    "\n",
    "        cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "        cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "    \n",
    "    cv2.imshow('result', img)\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "    # q to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release resources   \n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-source",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
